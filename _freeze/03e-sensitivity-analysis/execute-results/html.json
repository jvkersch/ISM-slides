{
  "hash": "539102a13d5f2eed754c35079977148d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Modeling and simulation of biosystems\"\nsubtitle: \"Sensitivity Analysis\"\nauthor: \"Joris Vankerschaver\"\nheader-includes:\n  - \\useinnertheme[shadow=true]{rounded}\n  - \\usecolortheme{rose}\n  - \\setbeamertemplate{footline}[frame number]\n  - \\usepackage{color}\n  - \\usepackage{graphicx}\noutput: \n  beamer_presentation:\n    theme: \"default\"\n    keep_tex: true\n    includes:\n      in_header: columns.tex\n---\n\n\n# Sensitivity Analysis\n\n## Why sensitivity analysis?\n\n- Verify what _sources of uncertainty_ contribute most to variance (uncertainty) of model output.\n- Sources of uncertainty in model can be\n    - Model parameters, initial conditions, inputs\n    - Model structure\n- Better understand changes in model predictions due to the above\n\n## Why sensitivity analysis?\n\n- Detect what _model parameters_ contribute most to model output uncertainty \n- Want to reduce model uncertainty, so best to focus on most influential parameters \n- Gives idea of correlation between parameters \n- Helps in choice of what parameters to estimate (in parameter estimation)\n\n## Why sensitivity analysis?\n\n- Gives information about interesting location, time, ... to collect experimental data\n- Basis for experimental design\n- Gives information on insensitive model parameters\n- Useful in model reduction of overparametrized models\n\n## Local vs global\n\n1. Local sensitivity analysis\n    - Determine sensitivity at **one certain point** in parameter space\n    - Not very computationally intensive\n    \\newline\n2. Global sensitivity analysis\n    - Determine sensitivity in **delimited area** of parameter space\n    - Usually gives a mean sensitivity\n    - Can become extremely computationally intensive\n\n- Each technique has advantages and disadvantages\n- Each technique gives different type of information\n    \n## Examples of sensitivity analysis: water quality model\n\n::::::: {.cols data-latex=\"\"}\n::: {.col data-latex=\"{0.55\\textwidth}\"}\n\n- Hundreds of parameters\n- Each model simulation takes days to run\n- Identifying highly sensitive parameters is critical\n\n![](./images/03e-sensitivity/wqm-model.png){width=75% align=\"center\"}\n:::\n\n::: {.col data-latex=\"{0.05\\textwidth}\"}\n\\mbox{}\n:::\n::: {.col data-latex=\"{0.55\\textwidth}\"}\n\n![](./images/03e-sensitivity/wqm-river.png){width=75%}\n![](./images/03e-sensitivity/wqm-parameters.png){width=75%}\n\n:::\n::::::\n\n\\scriptsize\nSource: *Developing a cloud-based toolbox for sensitivity analysis of a water quality model* (S. Kim et al, Environmental Modeling and Software, 2021)\n\n\n## Examples of sensitivity analysis: cell signaling\n\nToll-like signaling pathway:\n\n- Cellular response to external stimuli (e.g. infection)\n- Central role for NF-$\\kappa$B transcription factor\n- Shuttles back and forth between cytoplasm and nucleus\n\n\\centering\n![](./images/03e-sensitivity/nf-kappa-b-model.png){width=60%}\n\n\\scriptsize    \nSource: Images from _Fundamentals of Systems Biology_, M. Covert, CRC Press, 2014.\n\n\n## Examples of sensitivity analysis: cell signaling\n\nHoffmann-Levchenko (2005): Computational model for NF-$\\kappa$B\n\n::::::: {.cols data-latex=\"\"}\n::: {.col data-latex=\"{0.48\\textwidth}\"}\n\n- 25 ODEs, 36 parameters\n- Models protein production, degradation, transport\n- Important role for **parameter estimation** and **sensitivity analysis**\n\n:::\n\n::: {.col data-latex=\"{0.05\\textwidth}\"}\n\\mbox{}\n:::\n\n::: {.col data-latex=\"{0.48\\textwidth}\"}\n![](./images/03e-sensitivity/nf-kappa-b-equations.png)\n:::\n::::::\n\n\\scriptsize    \nSource: Images from _Fundamentals of Systems Biology_, M. Covert, CRC Press, 2014.\n\n\n## Examples of sensitivity analysis: cell signaling\n\nSensitivity analysis: which parameters affect the model the most?\n\n- Transcription rate: affects output a lot (**sensitive**)\n- Degradation rate: relatively **insensitive**\n\nGives rough idea, needs to be corroborated with full model.\n\n::::::: {.cols data-latex=\"\"}\n::: {.col data-latex=\"{0.48\\textwidth}\"}\n![](./images/03e-sensitivity/nf-kappa-b-oscillations.png){width=90%}\n:::\n\n::: {.col data-latex=\"{0.05\\textwidth}\"}\n\\mbox{}\n:::\n\n::: {.col data-latex=\"{0.48\\textwidth}\"}\n![](./images/03e-sensitivity/nf-kappa-b-sensitivity.png)\n:::\n::::::\n\n\\scriptsize    \nSource: Images from _Fundamentals of Systems Biology_, M. Covert, CRC Press, 2014.\n\n    \n# Local sensitivity analysis    \n\n## Local sensitivity analysis\n\n- How sensitive is model output ($y$) to changes of model parameter ($\\theta$) at one single point in parameter space\n- Mathematically: partial derivative of variable to parameter (_absolute sensitivity_, 1 number) at single point in parameter space\n$$\\frac{\\partial y}{\\partial \\theta}$$\n- Dynamical models: $y$ varies over time, hence also sensitivity varies over time $\\rightarrow$ _(absolute) sensitivity function_ \n$$\\frac{\\partial y(t)}{\\partial \\theta}=S(t)$$\n- For a single output, sensitivity functions for each individual parameter $\\theta_j$ can be determined\n\n## Local sensitivity analysis: absolute sensitivity\n\n- Often $y(t)$ can only be numerically determined, then also $S(t)$\n- Finite difference method: \\alert{forward difference}\n\\[\n\\left.\\frac{\\Delta y(t)}{\\Delta \\theta_j}\\right|_+  \n  =  \\frac{y(t,\\theta_j+\\Delta\\theta_j)-y(t,\\theta_j)}{\\Delta\\theta_j}\n\\]\n\n- Finite difference method: \\alert{backward difference}\n\\[\n\\left.\\frac{\\Delta y(t)}{\\Delta \\theta_j}\\right|_-  \n  = \\frac{y(t,\\theta_j)-y(t,\\theta_j-\\Delta\\theta_j)}{\\Delta\\theta_j}\n\\]\n\n\n## Local sensitivity analysis: absolute sensitivity\n\n- How to choose perturbation $\\Delta\\theta_j$?\n  - Too large: approximation is not good\n  - Too small: numerical instabilities will set in.\n- In practice, choose $\\Delta \\theta_j$ \\alert{small} and \\alert{fixed}, e.g.\n\\[\n   \\Delta \\theta_j = 10^{-6}.\n\\]\n\n\\begin{exampleblock}{Convergence}\n  Both the forward and the backward difference agree with the derivative up to\n  order $\\Delta \\theta_j$:\n  \\[\n  \\frac{\\partial y(t)}{\\partial \\theta_j} = \n    \\left.\\frac{\\Delta y(t)}{\\Delta \\theta_j}\\right|_+\n    + \\mathcal{O}(\\Delta \\theta_j), \\quad\n  \\frac{\\partial y(t)}{\\partial \\theta_j} = \n    \\left.\\frac{\\Delta y(t)}{\\Delta \\theta_j}\\right|_-  \n    + \\mathcal{O}(\\Delta \\theta_j).\n  \\]\n\\end{exampleblock}\n\n\n## Local sensitivity analysis: absolute sensitivity\n\n- Finite difference method: \\alert{central difference}\n\\[\n\\frac{\\Delta y(t)}{\\Delta \\theta_j} =   \n    \\frac{y(t,\\theta_j+\\Delta\\theta_j) - y(t,\\theta_j-\\Delta\\theta_j)}{2\\Delta\\theta_j}\n\\]\n\n\\begin{exampleblock}{Convergence}\n  The central difference agrees with the derivative up to\n  order $(\\Delta \\theta_j)^2$:\n  \\[\n  \\frac{\\partial y(t)}{\\partial \\theta_j} = \n    \\frac{\\Delta y(t)}{\\Delta \\theta_j}\n    + \\mathcal{O}((\\Delta \\theta_j)^2).\n  \\]\n\\end{exampleblock}\n\n## Local sensitivity analysis: relative sensitivity\n\n- Want to compare sensitivities of different combinations of outputs and parameters \n\\newline\n- Absolute sensitivity is influenced by magnitude of variable/parameter\n\\newline\n- Use **relative sensitivity**\n\n## Local sensitivity analysis: relative sensitivity\n\n- Relative sensitivity w.r.t. parameter $\\dfrac{\\partial y(t)}{\\partial \\theta_j} \\cdot \\theta_j$ \\newline\nCompare sensitivity of _same variable_ w.r.t. _different parameters_\n\\newline\n- Relative sensitivity w.r.t. variable $\\dfrac{\\partial y_i(t)}{\\partial \\theta} \\cdot \\dfrac{1}{y_i}$ \\newline\nCompare sensitivity of _different variables_ w.r.t. _same parameter_\n\\newline\n- Total relative sensitivity $\\dfrac{\\partial y_i(t)}{\\partial \\theta_j} \\cdot \\dfrac{\\theta_j}{y_i}$ \\newline\nCompare all sensitivities, i.e., relative w.r.t. parameter and variable\n\n## Local sensitivity analysis\n\n- Relative sensitivities allow to __rank sensitivities__\n    - Choice parameters for parameter estimation\n    - Choice parameters for model reduction\n    - Choice for additional measurement or experimental determination of parameter (reduce sources of uncertainty)\n- Ranking __depends on nominal value of parameter__, can be different at different position in parameter space\n- How to compare continuous sensitivity functions?\n- Interest in specific time points\n    - Where measurements are available\n    - Where measurements will be collected\n    \n## Local sensitivity analysis\n\n- Create generic model with\n    - Outputs $y_i$, $i=1,\\ldots,v$\n    - Parameters $\\theta_j$, $j=1,\\ldots,p$\n    - Moments of measurements $t_k$, $k=1,\\ldots,N$\n- Total relative sensitivity of variable $y_i$ w.r.t. parameter $\\theta_j$ at moment $t_k$\n$$\nS_{i,j,k}=\\dfrac{\\partial y_i(t_k)}{\\partial \\theta_j} \\cdot \\dfrac{\\theta_j}{y_i}\n$$\n\n## Local sensitivity analysis\n\nImportance parameter is determined by its impact on _all_ variables \\newline\n$\\rightarrow$ sum and average over all variables \\newline\n$\\rightarrow$ take sign into account (square and root)\\newline\n__root mean square sensitivity for parameter__ $\\theta_j$\n$$\n\\delta_{j,k}^{rmsq}=\\sqrt{\\dfrac{\\sum_{i=1}^vS_{i,j,k}^2}{v}}\n$$\n\\ \\newline\n$\\delta_{j,k}^{rmsq}$ can be very variable from moment to moment \\newline\n$\\rightarrow$ sum and average over all time points\\newline\n__time mean root mean square sensitivity for parameter__ $\\theta_j$\n$$\n\\delta_j^{rmsq} = \\dfrac{1}{N}\\sum_{k=1}^N \\delta_{j,k}^{rmsq}\n$$\n\n## Local sensitivity analysis\n\n- Gives one single measure for sensitivity of parameter\n- Use this measure to determine importance of parameter\n- Obtained value depends on\n    - nominal parameter value: nonlinear models give different values at different location in parameter space (see also global sensitivity analysis)\n    - choice of time points is arbitrary: this can lead to different set of parameters that are best estimated using dataset (see also identifiability)\n- Modifications can be defined based on application/goal\n\n\n# Side track: Monte Carlo simulation\n\n## Monte Carlo simulation technique\n\n\n::::::: {.cols data-latex=\"\"}\n::: {.col data-latex=\"{0.65\\textwidth}\"}\n\n- Computational algorithm, based on \n  - Large number of simulations (thousands to millions)\n  - Repeated random sampling\n- Used for modeling of\n  - Climate and environment\n  - Nuclear reactions\n  - Financial systems\n  - Molecular dynamics\n  - ...\n- In this course:\n  - Global sensitivity analysis\n  - Uncertainty analysis\n    \n:::\n\n::: {.col data-latex=\"{0.05\\textwidth}\"}\n\\mbox{}\n:::\n::: {.col data-latex=\"{0.32\\textwidth}\"}\n![](./images/03e-sensitivity/mc-casino.png)\n![](./images/03e-sensitivity/mc-atomic-bomb.png)\n:::\n::::::\n    \n## Principles behind Monte Carlo\n\nAlgorithm:\n\n1. Draw random parameter samples\n2. For each sample, run simulation\n3. Aggregate results of simulations into quantity of interest (e.g. mean)\n    \nAdvantages:\n\n- Easy to implement/understand\n- Applicable to wide range of problems (model-agnostic)\n\nDisadvantages:\n\n- Relatively slow convergence (many simulations needed)\n- Requires information about parameter distributions\n    \n## Example: computing $\\pi$\n\n- Drop points uniformly at random in the square $[-1, 1] \\times [-1, 1]$\n- Count fraction for which $x^2 + y^2 < 1$\n- As $N \\to \\infty$, gives approximation for $\\pi/4$.\n\n::::::: {.cols data-latex=\"\"}\n::: {.col data-latex=\"{0.38\\textwidth}\"}\n![](./images/03e-sensitivity/mc-circle.png)\n:::\n\n::: {.col data-latex=\"{0.05\\textwidth}\"}\n\\mbox{}\n:::\n\n::: {.col data-latex=\"{0.58\\textwidth}\"}\n![](./images/03e-sensitivity/mc-pi-over-4.png)\n:::\n::::::\n\nApp available at [https://shiny-stats.fly.dev/monte-carlo/](https://shiny-stats.fly.dev/monte-carlo/).\n\n# Global sensitivity analysis (GSA)\n\n## Global sensitivity analysis (GSA)\n\n- Measure for sensitivity in delimited area in parameter space\n- PDFs for parameters need to be chosen/found (same as for uncertainty analysis)\n\n3 techniques will be discussed:\n\n- Standardized regression coefficients\n- Screening techniques\n- Variance decomposition\n\n## GSA: Standardized regression coefficients\n\n- Linear regression of Monte Carlo simulations\n- Each line is simulation of variable $y$ for different parameter set $\\Theta$, i.e., other point in parameter space\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03e-sensitivity-analysis_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=672 height=50%}\n:::\n:::\n\n\n- Figure: 100 simulations of dissolved oxygen, with $k_1, k_2$ sampled uniformly between $0.1$ and $0.8$.\n\n## GSA: Standardized regression coefficients\n\nIdea: \n\n- Consider outcomes at fixed time $T$\n- Quantify effect of parameters $\\theta_1, \\ldots \\theta_p$ through linear model\n\\[\n  y_{t = T} = b_1 \\theta_1 + \\cdots + b_p \\theta_p + \\epsilon\n\\]\n- Regression coefficient $b_i$ gives contribution of parameter $\\theta_i$ in explaining variance of $y_{t = T}$\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](03e-sensitivity-analysis_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=672 height=50%}\n:::\n:::\n\n\n\n## GSA: Standardized regression coefficients\n\n- Correct for spread on both parameter and output\n- Recalculate coefficients $b_i$ to $SRC$s\n$$\nSRC_{\\theta_i} = b_i \\cdot \\dfrac{\\sigma_{\\theta_i}}{\\sigma_y}\n$$\n- Sample standard deviations from \n  - vector $y_{t = T}$ for output\n  - parameter samples for parameter $\\theta_i$.\n\n\n## GSA: Standardized regression coefficients\n\n- For linear model in parameters that were examined, the total variance is explained by $SRC$s\n$$\\sum_i SRC_{\\theta_i}^2=1$$\n- For nonlinear models (in the parameters) _not_ all variance will be explained. The part that is explained is given by determination coefficient\n$$R^2=\\sum_{i=1}^n \\dfrac{(\\hat{y}_i-\\overline{y})^2}{(y_i-\\overline{y})^2}$$\n- $\\hat{y}_i$: prediction by regression model\n- Technique only valid if $R^2 > 0.7$\n\n## GSA: Screening techniques\n\n- Goal: obtain idea of importance of model parameters using only a limited number of simulations\n- Example of technique: Morris screening\n- Calculation of _elementary effect_ for $\\theta_i$\n$$EE_{\\theta_i} = \\dfrac{y(\\theta_i+\\Delta)-y(\\theta)}{\\Delta}$$\n- $\\Delta$ is a predetermined step size in parameter\n- Remark analogy with local sensitivity, however, step size much larger\n\n## GSA: Morris screening\n\n- Assume 2 parameters $\\theta_1$ and $\\theta_2$\n- Locations in parameters space chosen systematically\n\n<!-- \\begin{figure} -->\n<!-- \\includegraphics[width=.7\\textwidth]{images/temp/052.pdf} -->\n<!-- \\end{figure} -->\n\n## GSA: Morris screening\n\n- Vector of $EE$ (in this case 4)\n- Statistical analysis of this vector\n    - $\\mu_{EE_{\\theta_i}}$: indication on average effect of this parameter over entire parameter space; large value means important parameter and vice versa\n    - $\\sigma_{EE_{\\theta_i}}$: information about linear behaviour of parameter; large value means nonlinear parameter or parameter involved in interactions with other parameters\n- Do same for $\\theta_2$\n\n## GSA: Morris screening\n\n- Normally 2 simulations needed per $EE$\n- 1991: Morris introduced more efficient way\n\n<!-- \\begin{figure} -->\n<!-- \\includegraphics[width=.7\\textwidth]{images/temp/053.pdf} -->\n<!-- \\end{figure} -->\n\n- Number of simulations: \n\\begin{center}\n(number $EE$ per parameter)$\\cdot$(number parameters +1)\n\\end{center}\n\n## GSA: Variance decomposition\n\n- Goal: find share of each model parameter in variance of model output\n- Used for models that are strongly nonlinear or nonmonotonous\n- Example of model with 3 paramaters:\n$$\\sigma_y^2=\\sigma_1^2+\\sigma_2^2+\\sigma_3^2+\\sigma_{12}^2+\\sigma_{13}^2+\\sigma_{23}^2+\\sigma_{123}^2$$\n- Normalisation (i.e., divide by $\\sigma_y^2$) gives _sensitivity indices_\n$$1=S_1+S_2+S_3+S_{12}+S_{13}+S_{23}+S_{123}$$\n\\ \\newline \n\n- Indicate which fraction of total variance is determined by certain parameter or parameter combination\n\n## GSA: Variance decomposition\n\n- _Total sensitivity indices_\n\\begin{eqnarray*}\nS_{T1} & = & S_1 + S_{12} + S_{13} + S_{123} \\\\\nS_{T2} & = & S_2 + S_{12} + S_{23} + S_{123} \\\\\nS_{T3} & = & S_3 + S_{13} + S_{23} + S_{123} \n\\end{eqnarray*}\n- Give total contribution of a certain parameter, including interaction effects\n- Watch out: some contributions are counted multiple times, hence sum of all total sensitivity indices is no longer 1\n\n## GSA: Variance decomposition\n\n- Two techniques:\n    - FAST (Fourier Amplitude Sensitivity Test): uses Fourier decomposition of model output; can determine first order effects (total effects $\\rightarrow$ extendedFAST); computationally intensive ((ten) thousands of simulations)\n    - Sobol indices: uses multiple integrals, both first order and higher order effects; computationally expensive; less efficient than FAST\n",
    "supporting": [
      "03e-sensitivity-analysis_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}